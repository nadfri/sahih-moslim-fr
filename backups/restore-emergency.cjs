#!/usr/bin/env node

const { execSync } = require("child_process");
const fs = require("fs");
const path = require("path");
const readline = require("readline");

console.log("ğŸš€ Script de restauration d'urgence pour Supabase - v2.0");
console.log("ğŸ”„ Compatible avec le nouveau schÃ©ma Prisma simplifiÃ©");
console.log("ğŸ“Š Support des relations Many-to-Many Hadith <-> Sahaba");
console.log("=======================================================\n");

// Fonction pour crÃ©er une interface interactive
function createInterface() {
  return readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
}

// Fonction pour poser une question Ã  l'utilisateur
function askQuestion(rl, question) {
  return new Promise((resolve) => {
    rl.question(question, (answer) => {
      resolve(answer.trim());
    });
  });
}

// Chemin du fichier de sauvegarde
const backupDir = path.join(__dirname);
const dumpFiles = fs
  .readdirSync(backupDir)
  .filter((file) => file.endsWith(".dump") || file.endsWith(".sql"));

if (dumpFiles.length === 0) {
  console.error(
    "âŒ Aucun fichier .dump ou .sql trouvÃ© dans le dossier backups"
  );
  process.exit(1);
}

// Trier par date (le plus rÃ©cent en premier)
dumpFiles.sort((a, b) => {
  const statA = fs.statSync(path.join(backupDir, a));
  const statB = fs.statSync(path.join(backupDir, b));
  return statB.mtime - statA.mtime;
});

console.log(`ğŸ“ Fichiers de sauvegarde disponibles (${dumpFiles.length}):`);
dumpFiles.forEach((file, index) => {
  const filePath = path.join(backupDir, file);
  const stats = fs.statSync(filePath);
  const size = (stats.size / 1024 / 1024).toFixed(2);
  const date = stats.mtime.toLocaleString("fr-FR");
  console.log(`  ${index + 1}. ${file} (${size} MB) - ${date}`);
});

let backupFile;

async function selectBackupFile() {
  if (dumpFiles.length === 1) {
    console.log("\nğŸ“ Un seul fichier trouvÃ©, utilisation automatique");
    backupFile = path.join(backupDir, dumpFiles[0]);
  } else {
    const rl = createInterface();

    try {
      const choice = await askQuestion(
        rl,
        `\nğŸ” Choisissez un fichier (1-${dumpFiles.length}) ou appuyez EntrÃ©e pour le plus rÃ©cent: `
      );

      if (choice === "" || choice === "1") {
        backupFile = path.join(backupDir, dumpFiles[0]);
        console.log(
          `ğŸ“ Utilisation du fichier le plus rÃ©cent: ${dumpFiles[0]}`
        );
      } else {
        const index = parseInt(choice) - 1;
        if (index >= 0 && index < dumpFiles.length) {
          backupFile = path.join(backupDir, dumpFiles[index]);
          console.log(
            `ğŸ“ Utilisation du fichier sÃ©lectionnÃ©: ${dumpFiles[index]}`
          );
        } else {
          console.error(`âŒ Choix invalide: ${choice}`);
          rl.close();
          process.exit(1);
        }
      }
    } finally {
      rl.close();
    }
  }
}

// ExÃ©cuter la sÃ©lection du fichier
selectBackupFile()
  .then(() => {
    // Continuer avec le reste du script...
    checkBackupFile();
  })
  .catch((error) => {
    console.error("âŒ Erreur lors de la sÃ©lection du fichier:", error.message);
    process.exit(1);
  });

function checkBackupFile() {
  // VÃ©rifier que le fichier existe
  if (!fs.existsSync(backupFile)) {
    console.error("âŒ Fichier de sauvegarde introuvable:", backupFile);
    process.exit(1);
  }

  console.log("âœ… Fichier de sauvegarde trouvÃ©");

  // Lire les variables d'environnement
  console.log("\nğŸ” Lecture des variables d'environnement...");
  const envPath = path.join(__dirname, "..", ".env");

  if (!fs.existsSync(envPath)) {
    console.error("âŒ Fichier .env introuvable");
    process.exit(1);
  }

  const envContent = fs.readFileSync(envPath, "utf8");
  const dbUrlMatch =
    envContent.match(/DATABASE_URL=(.+)/) ||
    envContent.match(/DIRECT_URL=(.+)/);

  if (!dbUrlMatch) {
    console.error("âŒ DATABASE_URL ou DIRECT_URL non trouvÃ©e dans .env");
    console.log("Contenu du fichier .env:");
    console.log(envContent);
    process.exit(1);
  }

  const dbUrl = dbUrlMatch[1].replace(/['"]/g, "").trim();

  // Nettoyer l'URL Supabase des paramÃ¨tres problÃ©matiques
  let cleanDbUrl = dbUrl;
  const isSupabaseRaw = dbUrl.includes("supabase") || dbUrl.includes("pooler");

  if (isSupabaseRaw) {
    // Supprimer les paramÃ¨tres de query qui causent des problÃ¨mes avec psql
    cleanDbUrl = dbUrl.replace(/\?.*$/, "");
    console.log("ğŸ§¹ URL nettoyÃ©e pour Supabase");
  }

  console.log("âœ… URL de base de donnÃ©es trouvÃ©e");

  // DÃ©tecter Supabase
  const isSupabase =
    cleanDbUrl.includes("supabase") || cleanDbUrl.includes("pooler");
  console.log(
    `ğŸ” Type de base: ${isSupabase ? "Supabase" : "PostgreSQL standard"}`
  );

  console.log("\nğŸ§¹ VÃ©rification de l'Ã©tat actuel de la base...");

  try {
    // VÃ©rifier les tables existantes
    const checkCommand = `psql "${cleanDbUrl}" -c "SELECT COUNT(*) as table_count FROM information_schema.tables WHERE table_schema = 'public';"`;
    const result = execSync(checkCommand, { encoding: "utf8" });
    const tableCount = result.split("\n")[2]?.trim() || "0";
    console.log(`ğŸ“Š Tables actuelles: ${tableCount}`);

    if (parseInt(tableCount) > 0) {
      console.log(
        "âš ï¸  La base contient dÃ©jÃ  des tables. Continuer la restauration ?"
      );
    }
  } catch (error) {
    console.warn("âš ï¸  Impossible de vÃ©rifier l'Ã©tat actuel:", error.message);
  }

  console.log("\nğŸ§¹ Nettoyage prÃ©alable de la base...");

  // Supprimer tous les objets utilisateur existants - approche plus complÃ¨te
  const cleanupCommands = [
    // Supprimer d'abord les politiques RLS
    `psql "${cleanDbUrl}" -c "DROP POLICY IF EXISTS \\"Allow users select own profile\\" ON public.profiles CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP POLICY IF EXISTS \\"Allow users update own profile\\" ON public.profiles CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP POLICY IF EXISTS \\"Allow authenticated users to read chapters\\" ON public.Chapter CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP POLICY IF EXISTS \\"Allow authenticated users to read hadiths\\" ON public.Hadith CASCADE;"`,

    // Supprimer les tables (dans l'ordre inverse des dÃ©pendances)
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"HadithTransmitter\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"_HadithToSahaba\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"Hadith\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"Chapter\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"Transmitter\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"Sahaba\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"profiles\\" CASCADE;"`,
    `psql "${cleanDbUrl}" -c "DROP TABLE IF EXISTS public.\\"_prisma_migrations\\" CASCADE;"`,

    // Supprimer les types enum
    `psql "${cleanDbUrl}" -c "DROP TYPE IF EXISTS public.\\"Role\\" CASCADE;"`,

    // Nettoyer toutes les tables restantes dans le schÃ©ma public
    `psql "${cleanDbUrl}" -c "
    DO \$\$
    DECLARE
      table_name TEXT;
    BEGIN
      FOR table_name IN
        SELECT tablename
        FROM pg_tables
        WHERE schemaname = 'public'
        AND tablename NOT LIKE 'pg_%'
        AND tablename NOT LIKE 'sql_%'
      LOOP
        EXECUTE 'DROP TABLE IF EXISTS public.\\\"' || table_name || '\\\" CASCADE;';
      END LOOP;
    END
    \$\$;
  "`,
  ];

  for (const cmd of cleanupCommands) {
    try {
      execSync(cmd, { stdio: "pipe" });
      console.log("âœ… Objet nettoyÃ©");
    } catch (error) {
      // Ignorer les erreurs de nettoyage
      console.log("â„¹ï¸  Objet dÃ©jÃ  nettoyÃ© ou inexistant");
    }
  }

  console.log("âœ… Nettoyage terminÃ©");

  console.log("\nğŸ“Š Ã‰tape 2: Restauration complÃ¨te...");

  // Commande de restauration complÃ¨te (structure + donnÃ©es)
  const restoreCommand = [
    "pg_restore",
    `--dbname="${cleanDbUrl}"`,
    "--no-owner",
    "--no-privileges",
    "--exit-on-error",
    "--verbose",
    "--schema=public",
    `"${backupFile}"`,
  ].join(" ");

  console.log(
    `Commande: pg_restore "***" "${path.basename(backupFile)}" --schema=public`
  );

  console.log(`Commande: pg_restore "***" "${path.basename(backupFile)}"`);

  try {
    console.log("\nâ³ Restauration en cours... (cela peut prendre du temps)");
    execSync(restoreCommand, {
      stdio: "inherit",
      cwd: process.cwd(),
      maxBuffer: 1024 * 1024 * 50, // 50MB buffer
    });

    console.log("\nâœ… Restauration terminÃ©e avec succÃ¨s!");

    console.log("\nï¿½ Ã‰tape 3: Correction des politiques RLS...");

    // Commandes SQL pour corriger les rÃ´les et politiques RLS
    const rlsFixCommands = [
      `psql "${cleanDbUrl}" -c "BEGIN;"`,
      `psql "${cleanDbUrl}" -c "ALTER TABLE public.profiles ENABLE ROW LEVEL SECURITY;"`,
      `psql "${cleanDbUrl}" -c "ALTER TABLE public.profiles NO FORCE ROW LEVEL SECURITY;"`,
      `psql "${cleanDbUrl}" -c "
      DO \$\$
      DECLARE
        r RECORD;
      BEGIN
        FOR r IN SELECT policyname FROM pg_policies WHERE schemaname='public' AND tablename='profiles' LOOP
          EXECUTE format('DROP POLICY IF EXISTS %I ON public.profiles', r.policyname);
        END LOOP;
      END
      \$\$;
    "`,
      `psql "${cleanDbUrl}" -c "
      CREATE POLICY \\"Allow users select own profile\\"
        ON public.profiles
        FOR SELECT
        TO authenticated
        USING (id::text = auth.uid()::text);
    "`,
      `psql "${cleanDbUrl}" -c "GRANT SELECT ON public.profiles TO authenticated;"`,
      `psql "${cleanDbUrl}" -c "REVOKE SELECT ON public.profiles FROM anon;"`,
      `psql "${cleanDbUrl}" -c "GRANT SELECT, INSERT, UPDATE, DELETE ON public.profiles TO service_role;"`,
      `psql "${cleanDbUrl}" -c "COMMIT;"`,
    ];

    console.log("ğŸ”’ Configuration des politiques RLS...");

    for (const cmd of rlsFixCommands) {
      try {
        execSync(cmd, { stdio: "pipe" });
        console.log("âœ… Politique RLS configurÃ©e");
      } catch (error) {
        console.warn("âš ï¸ Erreur lors de la configuration RLS:", error.message);
      }
    }

    console.log("âœ… Politiques RLS corrigÃ©es");

    console.log("\nğŸ”— Ajout des relations et indexes...");

    // Script SQL pour relations et indexes
    const relationsAndIndexesSQL = `
    -- Suppression des indexes en doublon
    DROP INDEX IF EXISTS "Chapter_name_idx";
    DROP INDEX IF EXISTS "idx_chapter_name";
    DROP INDEX IF EXISTS "Chapter_slug_idx";
    DROP INDEX IF EXISTS "idx_chapter_slug";
    DROP INDEX IF EXISTS "Chapter_index_idx";
    DROP INDEX IF EXISTS "idx_chapter_index";
    DROP INDEX IF EXISTS "Hadith_chapterId_idx";
    DROP INDEX IF EXISTS "idx_hadith_chapterid";
    DROP INDEX IF EXISTS "Hadith_chapterId_numero_idx";
    DROP INDEX IF EXISTS "idx_hadith_chapterid_numero";
    DROP INDEX IF EXISTS "Hadith_matn_fr_idx";
    DROP INDEX IF EXISTS "idx_hadith_matn_fr";
    DROP INDEX IF EXISTS "Hadith_matn_ar_idx";
    DROP INDEX IF EXISTS "idx_hadith_matn_ar";
    DROP INDEX IF EXISTS "Hadith_matn_en_idx";
    DROP INDEX IF EXISTS "idx_hadith_matn_en";
    DROP INDEX IF EXISTS "Hadith_numero_idx";
    DROP INDEX IF EXISTS "idx_hadith_numero";
    DROP INDEX IF EXISTS "HadithTransmitter_hadithId_idx";
    DROP INDEX IF EXISTS "idx_ht_hadithid";
    DROP INDEX IF EXISTS "HadithTransmitter_transmitterId_idx";
    DROP INDEX IF EXISTS "idx_ht_transmitterid";
    DROP INDEX IF EXISTS "Sahaba_name_idx";
    DROP INDEX IF EXISTS "idx_sahaba_name";
    DROP INDEX IF EXISTS "Sahaba_slug_idx";
    DROP INDEX IF EXISTS "idx_sahaba_slug";
    DROP INDEX IF EXISTS "Transmitter_name_idx";
    DROP INDEX IF EXISTS "idx_transmitter_name";
    DROP INDEX IF EXISTS "Transmitter_slug_idx";
    DROP INDEX IF EXISTS "idx_transmitter_slug";

    -- CrÃ©ation de l'enum Role si absent
    DO $$
    BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'Role') THEN
        CREATE TYPE "Role" AS ENUM ('USER', 'ADMIN');
      END IF;
    END $$;

    -- Foreign key Hadith.chapterId -> Chapter.id
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints
        WHERE constraint_name = 'fk_hadith_chapter' AND table_name = 'Hadith'
      ) THEN
        ALTER TABLE public."Hadith"
          ADD CONSTRAINT fk_hadith_chapter FOREIGN KEY ("chapterId") REFERENCES public."Chapter"(id) ON DELETE NO ACTION ON UPDATE NO ACTION;
      END IF;
    END $$;

    -- Foreign key HadithTransmitter.hadithId -> Hadith.id
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints
        WHERE constraint_name = 'fk_ht_hadith' AND table_name = 'HadithTransmitter'
      ) THEN
        ALTER TABLE public."HadithTransmitter"
          ADD CONSTRAINT fk_ht_hadith FOREIGN KEY ("hadithId") REFERENCES public."Hadith"(id) ON DELETE CASCADE ON UPDATE NO ACTION;
      END IF;
    END $$;

    -- Foreign key HadithTransmitter.transmitterId -> Transmitter.id
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints
        WHERE constraint_name = 'fk_ht_transmitter' AND table_name = 'HadithTransmitter'
      ) THEN
        ALTER TABLE public."HadithTransmitter"
          ADD CONSTRAINT fk_ht_transmitter FOREIGN KEY ("transmitterId") REFERENCES public."Transmitter"(id) ON DELETE CASCADE ON UPDATE NO ACTION;
      END IF;
    END $$;

    -- Foreign keys pour _HadithToSahaba (relation many-to-many simplifiÃ©e)
    DO $$
    BEGIN
      -- VÃ©rifier que la table _HadithToSahaba existe
      IF EXISTS (
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = '_HadithToSahaba'
      ) THEN
        -- Foreign key A -> Hadith.id
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.table_constraints
          WHERE constraint_name = '_HadithToSahaba_A_fkey' AND table_name = '_HadithToSahaba'
        ) THEN
          ALTER TABLE public."_HadithToSahaba"
            ADD CONSTRAINT "_HadithToSahaba_A_fkey" FOREIGN KEY ("A") REFERENCES public."Hadith"(id) ON DELETE CASCADE ON UPDATE CASCADE;
        END IF;
        
        -- Foreign key B -> Sahaba.id
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.table_constraints
          WHERE constraint_name = '_HadithToSahaba_B_fkey' AND table_name = '_HadithToSahaba'
        ) THEN
          ALTER TABLE public."_HadithToSahaba"
            ADD CONSTRAINT "_HadithToSahaba_B_fkey" FOREIGN KEY ("B") REFERENCES public."Sahaba"(id) ON DELETE CASCADE ON UPDATE CASCADE;
        END IF;
      END IF;
    END $$;

    -- Indexes optimisÃ©s selon le nouveau schÃ©ma Prisma
    CREATE INDEX IF NOT EXISTS "idx_hadith_chapterid" ON public."Hadith"("chapterId");
    CREATE INDEX IF NOT EXISTS "idx_hadith_numero" ON public."Hadith"("numero");
    CREATE INDEX IF NOT EXISTS "idx_hadith_chapterid_numero" ON public."Hadith"("chapterId", "numero");
    CREATE INDEX IF NOT EXISTS "idx_hadith_matn_fr" ON public."Hadith"("matn_fr");
    CREATE INDEX IF NOT EXISTS "idx_hadith_matn_ar" ON public."Hadith"("matn_ar");
    CREATE INDEX IF NOT EXISTS "idx_hadith_matn_en" ON public."Hadith"("matn_en");
    
    CREATE INDEX IF NOT EXISTS "idx_chapter_index" ON public."Chapter"("index");
    CREATE INDEX IF NOT EXISTS "idx_chapter_slug" ON public."Chapter"("slug");
    CREATE INDEX IF NOT EXISTS "idx_chapter_name_fr" ON public."Chapter"("name_fr");
    CREATE INDEX IF NOT EXISTS "idx_chapter_name_ar" ON public."Chapter"("name_ar");
    CREATE INDEX IF NOT EXISTS "idx_chapter_name_en" ON public."Chapter"("name_en");
    
    CREATE INDEX IF NOT EXISTS "idx_sahaba_slug" ON public."Sahaba"("slug");
    CREATE INDEX IF NOT EXISTS "idx_sahaba_name_fr" ON public."Sahaba"("name_fr");
    CREATE INDEX IF NOT EXISTS "idx_sahaba_name_ar" ON public."Sahaba"("name_ar");
    CREATE INDEX IF NOT EXISTS "idx_sahaba_name_en" ON public."Sahaba"("name_en");
    
    CREATE INDEX IF NOT EXISTS "idx_transmitter_slug" ON public."Transmitter"("slug");
    CREATE INDEX IF NOT EXISTS "idx_transmitter_name_fr" ON public."Transmitter"("name_fr");
    CREATE INDEX IF NOT EXISTS "idx_transmitter_name_ar" ON public."Transmitter"("name_ar");
    CREATE INDEX IF NOT EXISTS "idx_transmitter_name_en" ON public."Transmitter"("name_en");
    
    CREATE INDEX IF NOT EXISTS "idx_ht_hadithid" ON public."HadithTransmitter"("hadithId");
    CREATE INDEX IF NOT EXISTS "idx_ht_transmitterid" ON public."HadithTransmitter"("transmitterId");
    
    -- Index spÃ©cial pour la table de jointure _HadithToSahaba
    DO $$
    BEGIN
      IF EXISTS (
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_name = '_HadithToSahaba'
      ) THEN
        CREATE INDEX IF NOT EXISTS "_HadithToSahaba_B_index" ON public."_HadithToSahaba"("B");
      END IF;
    END $$;

    -- Contraintes uniques nÃ©cessaires
    DO $$
    BEGIN
      -- Contrainte unique pour HadithTransmitter
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints
        WHERE constraint_name = 'HadithTransmitter_hadithId_transmitterId_key' AND table_name = 'HadithTransmitter'
      ) THEN
        ALTER TABLE public."HadithTransmitter"
          ADD CONSTRAINT "HadithTransmitter_hadithId_transmitterId_key" UNIQUE ("hadithId", "transmitterId");
      END IF;
      
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints
        WHERE constraint_name = 'HadithTransmitter_hadithId_order_key' AND table_name = 'HadithTransmitter'
      ) THEN
        ALTER TABLE public."HadithTransmitter"
          ADD CONSTRAINT "HadithTransmitter_hadithId_order_key" UNIQUE ("hadithId", "order");
      END IF;
    END $$;
    `;

    // ExÃ©cution du script SQL via psql
    try {
      // Ã‰crire le SQL dans un fichier temporaire
      const sqlFilePath = path.join(__dirname, "relations_and_indexes.sql");
      fs.writeFileSync(sqlFilePath, relationsAndIndexesSQL, {
        encoding: "utf8",
      });
      // ExÃ©cuter le fichier avec psql
      const execIndexCmd = `psql "${cleanDbUrl}" -v ON_ERROR_STOP=1 -f "${sqlFilePath}"`;
      execSync(execIndexCmd, { stdio: "inherit" });
      // Supprimer le fichier temporaire
      fs.unlinkSync(sqlFilePath);
      console.log("âœ… Relations et indexes ajoutÃ©s");
    } catch (error) {
      console.warn(
        "âš ï¸ Erreur lors de l'ajout des relations/indexes:",
        error.message
      );
    }

    console.log("\nğŸ‰ Restauration terminÃ©e!");
    console.log(
      "ğŸ”„ ExÃ©cution de `prisma generate` pour synchroniser le client..."
    );

    // ExÃ©cuter prisma generate pour s'assurer que le client est Ã  jour
    try {
      const generateCommand = "cd .. && npx prisma generate";
      execSync(generateCommand, { stdio: "inherit" });
      console.log("âœ… Prisma Client gÃ©nÃ©rÃ© avec succÃ¨s");
    } catch (error) {
      console.warn(
        "âš ï¸ Erreur lors de la gÃ©nÃ©ration du client Prisma:",
        error.message
      );
      console.log("ğŸ’¡ Vous pouvez exÃ©cuter manuellement: npx prisma generate");
    }

    console.log("\nğŸ“Š VÃ©rification finale...");

    // VÃ©rification finale des donnÃ©es
    try {
      const verifyCommands = [
        `psql "${cleanDbUrl}" -c "SELECT COUNT(*) as hadith_count FROM public.\\"Hadith\\";"`,
        `psql "${cleanDbUrl}" -c "SELECT COUNT(*) as sahaba_count FROM public.\\"Sahaba\\";"`,
        `psql "${cleanDbUrl}" -c "SELECT COUNT(*) as chapter_count FROM public.\\"Chapter\\";"`,
        `psql "${cleanDbUrl}" -c "SELECT COUNT(*) as transmitter_count FROM public.\\"Transmitter\\";"`,
      ];

      console.log("ğŸ“ˆ Statistiques de la base restaurÃ©e:");
      verifyCommands.forEach((cmd) => {
        try {
          const result = execSync(cmd, { encoding: "utf8" });
          const lines = result.split("\n");
          const countLine = lines.find(
            (line) =>
              line.trim() && !line.includes("-") && !line.includes("count")
          );
          if (countLine) {
            const tableName = cmd.includes("hadith")
              ? "Hadiths"
              : cmd.includes("sahaba")
                ? "Sahabas"
                : cmd.includes("chapter")
                  ? "Chapitres"
                  : "Transmetteurs";
            console.log(`   - ${tableName}: ${countLine.trim()}`);
          }
        } catch (error) {
          console.log(`   - Erreur lors de la vÃ©rification`);
        }
      });
    } catch (error) {
      console.warn("âš ï¸ Impossible de vÃ©rifier les statistiques");
    }

    console.log("\nğŸ‰ Restauration complÃ¨te terminÃ©e!");
    console.log("ğŸ”„ Vous pouvez maintenant :");
    console.log("   1. AccÃ©der Ã  l'admin de votre application");
    console.log(
      "   2. VÃ©rifier que les relations Hadith <-> Sahaba fonctionnent"
    );
    console.log(
      "   3. Tester les fonctionnalitÃ©s multilingues (name_fr, name_en, name_ar)"
    );
  } catch (error) {
    console.error("\nâŒ Erreur lors de la restauration:");
    console.error(error.message);

    if (error.message.includes("event trigger")) {
      console.log("\nğŸ’¡ Conseil: Cette erreur est normale avec Supabase.");
      console.log(
        "   Les objets systÃ¨me sont protÃ©gÃ©s et ne peuvent pas Ãªtre modifiÃ©s."
      );
    }

    if (error.message.includes("already exists")) {
      console.log("\nğŸ’¡ Conseil: Certaines tables existent dÃ©jÃ .");
      console.log("   Utilisez --clean si vous voulez les remplacer.");
    }

    process.exit(1);
  }
}
